import torch
print(torch.cuda.is_available())


print(torch.version.cuda)
print(torch.backends.cudnn.version())


import torch
print(torch.cuda.current_device())  # Prints the current GPU ID
print(torch.cuda.get_device_name(torch.cuda.current_device()))  # Prints the GPU name


import json


with open("response.json") as file:
    responses = json.load(file)


len(responses)


import pandas as pd


df = pd.DataFrame(responses)
df


test_df = df.iloc[:100]
test_df


test_df_eval = test_df[["task_id","generated_output"]]
test_df_eval


custom_json = test_df.groupby("task_id")["generated_output"].apply(list).to_dict()
custom_json


with open("custom.json","w") as file:
    json.dump(custom_json,file)


response_df = df[["task_id","generated_output"]]
all_codes_json = response_df.groupby("task_id")["generated_output"].apply(list).to_dict()

print(len(all_codes_json))


with open("all_codes.json","w") as file:
    json.dump(all_codes_json, file)


with open("response.json") as file:
    response = json.load(file)

len(response)


print("hello")



