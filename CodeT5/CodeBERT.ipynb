{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1776de18-b9c9-44b6-8e03-c4fd9672445d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import ast\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset \n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import T5ForConditionalGeneration, RobertaTokenizer\n",
    "\n",
    "from transformers import AdamW\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "076133b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import infer_auto_device_map, init_empty_weights\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from torch.cuda.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0249190",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d40eb3ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Allocations           |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc4a7d9",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72a75cea-abc2-4431-8d74-cab1407181e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem_id</th>\n",
       "      <th>summary</th>\n",
       "      <th>prompt</th>\n",
       "      <th>solution</th>\n",
       "      <th>generated_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1053</td>\n",
       "      <td>The code compiles but does not pass any tests....</td>\n",
       "      <td>Chef has a binary array in an unsorted manner....</td>\n",
       "      <td>[\"# cook your dish here\\nfor _ in range(int(in...</td>\n",
       "      <td>def solve():\\n  n = int(input())\\n  arr = list...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2645</td>\n",
       "      <td>The code compiles and passes all tests. It has...</td>\n",
       "      <td>=====Function Descriptions=====\\nitertools.com...</td>\n",
       "      <td>[\"from itertools import *\\ns,n = input().split...</td>\n",
       "      <td>def solve():\\n  n = int(input())\\n  arr = list...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3325</td>\n",
       "      <td>The code compiles and passes some tests but no...</td>\n",
       "      <td>Given a string, s, return a new string that or...</td>\n",
       "      <td>[\"from collections import Counter\\n\\ndef most_...</td>\n",
       "      <td>def solve():\\n  n = int(input())\\n  arr = list...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2336</td>\n",
       "      <td>The code fails to compile. Fix compilation iss...</td>\n",
       "      <td>Petr likes to come up with problems about rand...</td>\n",
       "      <td>[\"n = int(input())\\nl = [int(x) - 1 for x in i...</td>\n",
       "      <td>def solve():\\n  n = int(input())\\n  arr = list...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4377</td>\n",
       "      <td>The code fails to compile. Fix compilation iss...</td>\n",
       "      <td>Alice and Bob have participated to a Rock Off ...</td>\n",
       "      <td>[\"def solve(a, b):\\n    alice = sum(i &gt; j for ...</td>\n",
       "      <td>def solve():\\n  n = int(input())\\n  arr = list...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   problem_id                                            summary  \\\n",
       "0        1053  The code compiles but does not pass any tests....   \n",
       "1        2645  The code compiles and passes all tests. It has...   \n",
       "2        3325  The code compiles and passes some tests but no...   \n",
       "3        2336  The code fails to compile. Fix compilation iss...   \n",
       "4        4377  The code fails to compile. Fix compilation iss...   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Chef has a binary array in an unsorted manner....   \n",
       "1  =====Function Descriptions=====\\nitertools.com...   \n",
       "2  Given a string, s, return a new string that or...   \n",
       "3  Petr likes to come up with problems about rand...   \n",
       "4  Alice and Bob have participated to a Rock Off ...   \n",
       "\n",
       "                                            solution  \\\n",
       "0  [\"# cook your dish here\\nfor _ in range(int(in...   \n",
       "1  [\"from itertools import *\\ns,n = input().split...   \n",
       "2  [\"from collections import Counter\\n\\ndef most_...   \n",
       "3  [\"n = int(input())\\nl = [int(x) - 1 for x in i...   \n",
       "4  [\"def solve(a, b):\\n    alice = sum(i > j for ...   \n",
       "\n",
       "                                    generated_output  \n",
       "0  def solve():\\n  n = int(input())\\n  arr = list...  \n",
       "1  def solve():\\n  n = int(input())\\n  arr = list...  \n",
       "2  def solve():\\n  n = int(input())\\n  arr = list...  \n",
       "3  def solve():\\n  n = int(input())\\n  arr = list...  \n",
       "4  def solve():\\n  n = int(input())\\n  arr = list...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_summary_df = pd.read_csv(\"./Error Generation/results/error_summary.csv\")\n",
    "error_summary_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0255303",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_summary_df = error_summary_df.set_index(\"problem_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcdb2f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>prompt</th>\n",
       "      <th>solution</th>\n",
       "      <th>generated_output</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>problem_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>The code compiles but does not pass any tests....</td>\n",
       "      <td>Chef has a binary array in an unsorted manner....</td>\n",
       "      <td>[\"# cook your dish here\\nfor _ in range(int(in...</td>\n",
       "      <td>def solve():\\n  n = int(input())\\n  arr = list...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2645</th>\n",
       "      <td>The code compiles and passes all tests. It has...</td>\n",
       "      <td>=====Function Descriptions=====\\nitertools.com...</td>\n",
       "      <td>[\"from itertools import *\\ns,n = input().split...</td>\n",
       "      <td>def solve():\\n  n = int(input())\\n  arr = list...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3325</th>\n",
       "      <td>The code compiles and passes some tests but no...</td>\n",
       "      <td>Given a string, s, return a new string that or...</td>\n",
       "      <td>[\"from collections import Counter\\n\\ndef most_...</td>\n",
       "      <td>def solve():\\n  n = int(input())\\n  arr = list...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2336</th>\n",
       "      <td>The code fails to compile. Fix compilation iss...</td>\n",
       "      <td>Petr likes to come up with problems about rand...</td>\n",
       "      <td>[\"n = int(input())\\nl = [int(x) - 1 for x in i...</td>\n",
       "      <td>def solve():\\n  n = int(input())\\n  arr = list...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4377</th>\n",
       "      <td>The code fails to compile. Fix compilation iss...</td>\n",
       "      <td>Alice and Bob have participated to a Rock Off ...</td>\n",
       "      <td>[\"def solve(a, b):\\n    alice = sum(i &gt; j for ...</td>\n",
       "      <td>def solve():\\n  n = int(input())\\n  arr = list...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      summary  \\\n",
       "problem_id                                                      \n",
       "1053        The code compiles but does not pass any tests....   \n",
       "2645        The code compiles and passes all tests. It has...   \n",
       "3325        The code compiles and passes some tests but no...   \n",
       "2336        The code fails to compile. Fix compilation iss...   \n",
       "4377        The code fails to compile. Fix compilation iss...   \n",
       "\n",
       "                                                       prompt  \\\n",
       "problem_id                                                      \n",
       "1053        Chef has a binary array in an unsorted manner....   \n",
       "2645        =====Function Descriptions=====\\nitertools.com...   \n",
       "3325        Given a string, s, return a new string that or...   \n",
       "2336        Petr likes to come up with problems about rand...   \n",
       "4377        Alice and Bob have participated to a Rock Off ...   \n",
       "\n",
       "                                                     solution  \\\n",
       "problem_id                                                      \n",
       "1053        [\"# cook your dish here\\nfor _ in range(int(in...   \n",
       "2645        [\"from itertools import *\\ns,n = input().split...   \n",
       "3325        [\"from collections import Counter\\n\\ndef most_...   \n",
       "2336        [\"n = int(input())\\nl = [int(x) - 1 for x in i...   \n",
       "4377        [\"def solve(a, b):\\n    alice = sum(i > j for ...   \n",
       "\n",
       "                                             generated_output  \n",
       "problem_id                                                     \n",
       "1053        def solve():\\n  n = int(input())\\n  arr = list...  \n",
       "2645        def solve():\\n  n = int(input())\\n  arr = list...  \n",
       "3325        def solve():\\n  n = int(input())\\n  arr = list...  \n",
       "2336        def solve():\\n  n = int(input())\\n  arr = list...  \n",
       "4377        def solve():\\n  n = int(input())\\n  arr = list...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_summary_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c508ef7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_summary_df[\"solution\"] = error_summary_df[\"solution\"].apply(lambda x: ast.literal_eval(x) if isinstance(x,str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e06ce52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import ast\n",
    "\n",
    "def generate_input_output_pairs(df):\n",
    "    input_output_pairs = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        # Ensure 'solution' is a list\n",
    "        if isinstance(row['solution'], str):\n",
    "            solutions = ast.literal_eval(row['solution'])  # Convert string to list\n",
    "        else:\n",
    "            solutions = row['solution']\n",
    "        \n",
    "        # Shuffle the solutions and pick one\n",
    "        if solutions and isinstance(solutions, list):\n",
    "            index = random.randrange(0,len(solutions))\n",
    "            expected_output = solutions[index]\n",
    "        else:\n",
    "            expected_output = \"No valid solution\"\n",
    "\n",
    "        # Generate the input text\n",
    "        input_text = (\n",
    "            f\"\"\"Generated_output: {row['generated_output']}, expected_output: {expected_output} \"\"\"\n",
    "            f\"\"\"What is the error or difference?\"\"\"\n",
    "        )\n",
    "        \n",
    "        # The output text is the summary\n",
    "        output_text = row['summary']\n",
    "\n",
    "        # Append the pair to the list\n",
    "        input_output_pairs.append((input_text, output_text))\n",
    "\n",
    "    return input_output_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f39b742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Generated_output: def solve():\\n  n = int(input())\\n  arr = list(map(int, input().split()))\\n  arr.sort()\\n  \\n  for i in range(n - 1):\\n    if arr[i] == 0 and arr[i+1] == 1:\\n      print(i)\\n      return\\n\\n  print(n-1)\\n\\n\\nt = int(input())\\nfor _ in range(t):\\n  solve(), expected_output: # cook your dish here\\nt = int(input())\\nfor i in range(t):\\n    N = int(input())\\n    lst = list(map(int,input().split()))\\n    count = 0\\n    lst.sort()\\n    for j in lst:\\n        if j == 0 :\\n            count = count+1 \\n    print(count)        \\n What is the error or difference?', 'The code compiles but does not pass any tests. It has moderate similarity to the reference.')\n"
     ]
    }
   ],
   "source": [
    "training_data = generate_input_output_pairs(error_summary_df)\n",
    "print(training_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc5a08f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4882"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb8fba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(training_data, test_size = 0.09, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7665ae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    processed_data = []\n",
    "    for input_text, output_text in data:\n",
    "        processed_data.append({\n",
    "            'input_text': input_text,\n",
    "            'output_text': output_text\n",
    "        })\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "076f151c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_processed = preprocess_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81667bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_processed = preprocess_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98951c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_data.json', 'w') as train_file:\n",
    "    json.dump(train_data_processed, train_file, indent=4)\n",
    "\n",
    "with open('test_data.json', 'w') as test_file:\n",
    "    json.dump(test_data_processed, test_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6e5321",
   "metadata": {},
   "source": [
    "## FineTuning CodeT5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7147ec22",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Salesforce/codet5-base\"\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "with init_empty_weights():\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26ed8f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_map = infer_auto_device_map(model, max_memory={0: \"4GiB\", \"cpu\": \"8GiB\"})\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"Salesforce/codet5-base\", device_map=device_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8fbae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeT5Dataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length=512):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        input_text = item['input_text']\n",
    "        output_text = item['output_text']\n",
    "\n",
    "        # Tokenize inputs and labels\n",
    "        inputs = self.tokenizer(\n",
    "            input_text,\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        labels = self.tokenizer(\n",
    "            output_text,\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # Return tokenized inputs and labels\n",
    "        return {\n",
    "            \"input_ids\": inputs[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": inputs[\"attention_mask\"].squeeze(),\n",
    "            \"labels\": labels[\"input_ids\"].squeeze()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16491b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CodeT5Dataset(train_data_processed, tokenizer)\n",
    "test_dataset = CodeT5Dataset(test_data_processed, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4441d576",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34032a27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd1c6a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88090964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec368ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b88b1da",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26146d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65d3f7a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32100, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32100, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32100, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32100, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a3ff3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "gradient_accumulation_steps = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "48a5aad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sulav\\AppData\\Local\\Temp\\ipykernel_23596\\4292142752.py:1: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    }
   ],
   "source": [
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1bc4fb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:   0%|                                                                           | 0/4442 [00:00<?, ?batch/s]C:\\Users\\Sulav\\AppData\\Local\\Temp\\ipykernel_23596\\3104929819.py:20: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Epoch 1/3: 100%|██████████████████████████████| 4442/4442 [4:26:38<00:00,  3.60s/batch, batch_time=3.45s, loss=0.00187]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Loss: 0.0277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|█████████████████████████████| 4442/4442 [4:17:21<00:00,  3.48s/batch, batch_time=3.41s, loss=0.000556]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Average Loss: 0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|█████████████████████████████| 4442/4442 [4:21:22<00:00,  3.53s/batch, batch_time=3.43s, loss=0.000427]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Average Loss: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    # Wrap the DataLoader with tqdm for progress tracking\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs}\", unit=\"batch\")\n",
    "\n",
    "    for step, batch in enumerate(loop):\n",
    "        start_time = time.time()  # Start timer for the batch\n",
    "\n",
    "        # Move inputs to GPU\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        # Forward pass with mixed precision\n",
    "        with autocast():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss / gradient_accumulation_steps  # Scale loss for gradient accumulation\n",
    "\n",
    "        # Backward pass with scaled loss\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # Update the weights every `gradient_accumulation_steps`\n",
    "        if (step + 1) % gradient_accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()  # Clear accumulated gradients\n",
    "\n",
    "        # Accumulate loss for monitoring\n",
    "        epoch_loss += loss.item() * gradient_accumulation_steps  # Unscale the loss for reporting\n",
    "\n",
    "        # Update the tqdm progress bar\n",
    "        loop.set_postfix(\n",
    "            loss=loss.item(),  # Current batch loss\n",
    "            batch_time=f\"{time.time() - start_time:.2f}s\"  # Time taken for the batch\n",
    "        )\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Average Loss: {epoch_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "531f1e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_codet5\\\\tokenizer_config.json',\n",
       " './fine_tuned_codet5\\\\special_tokens_map.json',\n",
       " './fine_tuned_codet5\\\\vocab.json',\n",
       " './fine_tuned_codet5\\\\merges.txt',\n",
       " './fine_tuned_codet5\\\\added_tokens.json')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./fine_tuned_codet5\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_codet5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f5e6b0",
   "metadata": {},
   "source": [
    "### Testing the finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6e4a8f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Generated_output: def solve():\n",
      "  n = int(input())\n",
      "  arr = list(map(int, input().split()))\n",
      "  arr.sort()\n",
      "  \n",
      "  for i in range(n - 1):\n",
      "    if arr[i] == 0 and arr[i+1] == 1:\n",
      "      print(i)\n",
      "      return\n",
      "\n",
      "  print(n-1)\n",
      "\n",
      "\n",
      "t = int(input())\n",
      "for _ in range(t):\n",
      "  solve(), expected_output: class Solution:\n",
      "    def thousandSeparator(self, n: int) -> str:\n",
      "        arr = []\n",
      "        i, count = 0, 0\n",
      "        num = str(n)\n",
      "        while i < len(num):\n",
      "            if count != 3:\n",
      "                arr.append(num[~i])\n",
      "                i += 1\n",
      "                count += 1\n",
      "            else:\n",
      "                arr.append('.')\n",
      "                count = 0\n",
      "                \n",
      "        return ''.join(arr[::-1])\n",
      " What is the error or difference?\n",
      "Generated Output: The code fails to compile. Fix compilation issues first. It is significantly different from the reference.\n",
      "Expected Output: The code fails to compile. Fix compilation issues first. It is significantly different from the reference.\n",
      "\n",
      "Input: Generated_output: def solve():\n",
      "  n = int(input())\n",
      "  arr = list(map(int, input().split()))\n",
      "  arr.sort()\n",
      "  \n",
      "  for i in range(n - 1):\n",
      "    if arr[i] == 0 and arr[i+1] == 1:\n",
      "      print(i)\n",
      "      return\n",
      "\n",
      "  print(n-1)\n",
      "\n",
      "\n",
      "t = int(input())\n",
      "for _ in range(t):\n",
      "  solve(), expected_output: class Solution:\n",
      "    def maxAbsValExpr(self, A: List[int], B: List[int]) -> int:\n",
      "        n = len(A)\n",
      "        \n",
      "        max1 = max2 = max3 = max4 = -10**6 - 1 \n",
      "        min1 = min2 = min3 = min4 = 10**6 + 1\n",
      "        for i in range(n):\n",
      "            temp = A[i] - B[i] - i\n",
      "            min1 = min(min1,temp)\n",
      "            max1 = max(max1,temp)\n",
      "            \n",
      "            temp = A[i] + B[i] - i\n",
      "            min2 = min(min2,temp)\n",
      "            max2 = max(max2,temp)\n",
      "                       \n",
      "            temp = A[i] + B[i] + i\n",
      "            min3 = min(min3,temp)\n",
      "            max3 = max(max3,temp)\n",
      "            \n",
      "            temp = A[i] - B[i] +i\n",
      "            min4 = min(min4,temp)\n",
      "            max4 = max(max4,temp)\n",
      "        \n",
      "        ans = max(max4 - min4, max3 - min3, max2 - min2, max1 - min1)\n",
      "\n",
      "        return ans What is the error or difference?\n",
      "Generated Output: The code fails to compile. Fix compilation issues first. It is significantly different from the reference.\n",
      "Expected Output: The code fails to compile. Fix compilation issues first. It is significantly different from the reference.\n",
      "\n",
      "Input: Generated_output: def solve():\n",
      "  n = int(input())\n",
      "  arr = list(map(int, input().split()))\n",
      "  arr.sort()\n",
      "  \n",
      "  for i in range(n - 1):\n",
      "    if arr[i] == 0 and arr[i+1] == 1:\n",
      "      print(i)\n",
      "      return\n",
      "\n",
      "  print(n-1)\n",
      "\n",
      "\n",
      "t = int(input())\n",
      "for _ in range(t):\n",
      "  solve(), expected_output: f = lambda: map(int, input().split())\n",
      "n, k = f()\n",
      "p = sorted(f())\n",
      " \n",
      "m, d = n // k, n % k\n",
      "u, v = d + 1, k - d + 1\n",
      "g = [0] * u * v\n",
      " \n",
      "i = 0\n",
      "for a in range(u):\n",
      "    j = a * m + a - 1\n",
      "    for b in range(v):\n",
      "        x = g[i - 1] + p[j] - p[j - m + 1] if b else 9e9\n",
      "        y = g[i - v] + p[j] - p[j - m] if a else 9e9\n",
      "        if i: g[i] = min(x, y)\n",
      "        i += 1\n",
      "        j += m\n",
      "print(g[-1]) What is the error or difference?\n",
      "Generated Output: The code compiles and passes all tests. It is significantly different from the reference.\n",
      "Expected Output: The code fails to compile. Fix compilation issues first. It is significantly different from the reference.\n",
      "\n",
      "Input: Generated_output: def solve():\n",
      "  n = int(input())\n",
      "  arr = list(map(int, input().split()))\n",
      "  arr.sort()\n",
      "  \n",
      "  for i in range(n - 1):\n",
      "    if arr[i] == 0 and arr[i+1] == 1:\n",
      "      print(i)\n",
      "      return\n",
      "\n",
      "  print(n-1)\n",
      "\n",
      "\n",
      "t = int(input())\n",
      "for _ in range(t):\n",
      "  solve(), expected_output: # cook your dish here\n",
      "# cook your dish here\n",
      "import math\n",
      "test=int(input())\n",
      "for _ in range(test):\n",
      " n=int(input())\n",
      " l=list(map(int,input().split()))\n",
      " f=0\n",
      " for i in range(math.ceil(n//2)):\n",
      "  if n%2==1:\n",
      "   f=1\n",
      "   break\n",
      "  else:\n",
      "   if l[i]!=l[i+n//2]:\n",
      "    if min(l[i],l[i+n//2])==-1:\n",
      "     l[i]=max(l[i],l[i+n//2])\n",
      "     l[i+n//2]=max(l[i],l[i+n//2])\n",
      "    else:\n",
      "     f=1\n",
      "     break\n",
      "   else:\n",
      "    if l[i]==-1:\n",
      "     l[i]=1\n",
      "     l[i+n//2]=1\n",
      " if f==1:\n",
      "  print(\"NO\")\n",
      " else:\n",
      "  print(\"YES\")\n",
      "  print(*l) What is the error or difference?\n",
      "Generated Output: The code compiles and passes all tests. It has moderate similarity to the reference.\n",
      "Expected Output: The code compiles but crashes at runtime. Fix runtime errors next. It is significantly different from the reference.\n",
      "\n",
      "Input: Generated_output: def solve():\n",
      "  n = int(input())\n",
      "  arr = list(map(int, input().split()))\n",
      "  arr.sort()\n",
      "  \n",
      "  for i in range(n - 1):\n",
      "    if arr[i] == 0 and arr[i+1] == 1:\n",
      "      print(i)\n",
      "      return\n",
      "\n",
      "  print(n-1)\n",
      "\n",
      "\n",
      "t = int(input())\n",
      "for _ in range(t):\n",
      "  solve(), expected_output: def you_are_a_cube(cube):\n",
      "    x = round(abs(cube)**(1/3))\n",
      "    if x**3 == cube:\n",
      "        return True\n",
      "    else:\n",
      "        return False What is the error or difference?\n",
      "Generated Output: The code fails to compile. Fix compilation issues first. It is significantly different from the reference.\n",
      "Expected Output: The code fails to compile. Fix compilation issues first. It is significantly different from the reference.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_output(input_text):\n",
    "    model.eval()\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, padding=\"max_length\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(inputs[\"input_ids\"], max_length=512)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Test the model\n",
    "for test_case in test_data_processed[:5]:\n",
    "    input_text = test_case[\"input_text\"]\n",
    "    expected_output = test_case[\"output_text\"]\n",
    "\n",
    "    generated_output = generate_output(input_text)\n",
    "    print(f\"Input: {input_text}\")\n",
    "    print(f\"Generated Output: {generated_output}\")\n",
    "    print(f\"Expected Output: {expected_output}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc9e814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0528612c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e82cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eaf342",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
